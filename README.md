# myMeitu
简易版美图秀秀，前后端分离的照片+视频在线编辑及存储网站

## 问题记录

```te
1. 由于axios异步传输，由axios指定的结果必须在时延后才能访问到
2. 视频的设计：
    - 点击打开视频后，发起存储视频请求，后台存储10s的静态资源
    - 前端等待约12s后去访问静态资源，加载到页面中播放（人工设置时延虽然避免了长连接，但势必造成无法获取第一时间数据/发早了没更新导致白发）
    - 前端一旦加载到avi视频，立马去请求后端开始录制新的静态资源视频
    - 当前端播放完毕，（或许有点时延）也请求到了新的avi视频，尝试继续播放新视频
    也就是说——后台每十秒更新一遍缓存/output.avi，前端一旦访问到新的avi就尝试请求下一个新avi（在前端设置时延或者在后端被阻塞，以保证获取到更新后的）

3. 视频编码格式
    - 使用avi，mp4格式底层的编码方式似乎是互通的，但文件类型不同
    - 浏览器只支持某些视频的编码类型（至少<video>是）
    - avi格式在浏览器中会默认下载，而不会默认播放，mp4是即时播放

4. 浏览器缓存axios的get结果
    - 访问静态资源会缓存
    - 增加随机数参数没有作用
    - 前端（请求）和后端（响应）都可以禁止缓存，但当请求静态资源时，后台可以设置过滤器，前端直接改axios参数
    - 问题是：前端语法不熟练，responseType写入headers后就失效了
4.1 浏览器在输入框发起的get请求也会有缓存

5. 使用websocket优化
    - websocket工作逻辑：
        当后台录制好视频后，立马返回给前端一个消息，表示前端可以数据更新了
        由于后台返回的是个视频，不太好直接作为函数返回值返回，所以只能把视频存在本地，返回确认消息
    - websocket特点：
        和java开发不同，其使用生命周期/钩子的思想
```

### 潜在使用

```conc
1. cookie的使用
- Session Id
- 存储用户默认选项 language...
- 购物车信息
- 某些不必进数据库的信息（短期内需要维护的信息）


2. 优化视频效果
- 寻找真正生产环境下实时视频的模式
- 将redis，mySQL加入项目
- 适当解决点前端问题（直播不用<video>,而应该是别的）
- ##关于提高直播清晰度，提高项目性能
- 参考goEnjoy

3. 准备压测，优化代码/项目结构


4. 考虑是否需要微服务，Nginx等高级货  |   或者强行使用、暴力拆解项目
- 网关Gateway替代Filter过滤器


5. 对项目的分布式改造（终终终极）
```

```conc
myFFmpeg
H.264

1. 内部编码核心思想：

   - 空间冗余（相邻像素点之间相关性较强可以省略冗余）
   - 时间冗余（视频序列的相邻图像之间内容相似可以省略冗余）
   - 编码冗余（不同像素值出现的概率不同 + 哈夫曼？）
   - 视觉冗余（人的视觉系统对某些细节不敏感）

2. 压缩方法：

   分组：将几帧图像分为一组

   定义帧：将每组内各镇图像定义为三类帧 I，B，P

   预测帧：以I为基础帧，以I预测P帧，再由I和P预测B帧

   数据传输：将I帧数据和预测的信息插值存储传输

MJPEG
只有帧内压缩，不考虑算法复杂的帧间压缩
静态图像的JPEG压缩有两种基本算法：
- 基于DCT的有失真压缩算法
- 基于DPCM的无失真压缩算法


视频编码原理：

1. 由于RGB信息有冗余，转化成YUV更轻量级（1个亮度分量和2个色度分量，由于人眼对亮度信息更加敏感，对色度信息较弱，所以视频编码将Y和UV分开编码）

2. 每一帧图像，又划分成一个个宏块进行编码，大小是16x16（H264、VP8），32x32（H265、VP9），64x64（H265、VP9、AV1）

3. 图像一般有数据冗余，而视频编码就算为了在最后熵编码的适合压缩率更高，也就是在送到熵编码的像素串是一串含有很多0，且连续为0的串。

4. 先通过帧内预测/帧间预测去除空间冗余和时间冗余，得到一个像素值比编码块小的残差块，再通过DCT变换将低频和高频信息分离得到变化块，再对变化块的系数做量化。

   量化的结果就递交给熵编码
```

```conc
直播效果做成广播

1. 消息队列 多个服务器采用发布-订阅模式接收信息
2. 手写广播，封装DatagramPacket发送流程
3. 据说UDP可以实现广播
```

```conc
直播的实时评论效果

1. 消息队列： 双向订阅，一方发布直播内容，一方发布评论数据
2. 原生HTTP
```

```conc
手写图片转视频编码器

由于H264或者更加简单的编码方式也有点复杂，而现成的视频播放器只能识别共识的编码方式
那我只有自己编码 ， 自己解码 ———— 再手写视频播放器


TODO：
1. 压缩数据 
    - 帧内压缩
        - 色度子采样后
        - 变化编码（DCT离散余弦变换 将图像变换为频域）
        - 量化
        - 熵编码（哈夫曼 / 算数编码）
    - 帧间压缩
2. 制定协议，规定每帧大小 / 帧间分隔符 
3. 考虑如何传输 / 保存大文件
4. 解压



next：
- 了解前端canvas | 基本功能类似python的turtle，但可以监听鼠标事件，通过迭代调用
    画直线的方式（此刻的终点是下一刻的起点）完成实时绘画
- 图片相似度计算
    - 图片哈希 汉明距离
    - 深度学习处理相似度
- 接入AI
    - 功能简述（全靠百度大脑的API）
        - 是否有人脸、估计年龄、表情、性别，画出人脸范围正方形
        - （并不能）出于美图秀秀功能考虑：肤色、眼睛大小...Java暂无此功能
        - 
```
